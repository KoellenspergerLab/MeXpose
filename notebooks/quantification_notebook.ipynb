{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87e86d-a479-4ca5-ba40-f33b907d1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a51a3-512f-44d5-9728-e25d28d00ec9",
   "metadata": {},
   "source": [
    "## Quantification\n",
    "\n",
    "This notebook provides functionality to perform quantification using external standards. It is tailored towards LA-ICP-TOFMS data but can be adapted to accomodate other data types.  \n",
    "The notebook expects 3 CSV files: 1) single-cell CSV (e.g. obtained from the data_extraction notebook); 2) 'standards summary' CSV (e.g. exported ROIs from the *image_reconstruction* notebook); 3) 'amounts' CSV.\n",
    "\n",
    "1. **Single-cell CSV file(s)**  \n",
    "   Measured integrated isotope counts in single-cells (e.g. output of *data_extraction* notebook).\n",
    "\n",
    "   **Example:**\n",
    "   <table>\n",
    "     <tr><th>cell_label</th><th>56Fe</th><th>63Cu</th><th>...</th></tr>\n",
    "     <tr><td>1</t><td>12345</td><td>6789</td><td>...</td></tr>\n",
    "     <tr><td>2</t><td>23456</td><td>7890</td><td>...</td></tr>\n",
    "     <tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
    "   </table>\n",
    "\n",
    "2. **Standards Summary CSV**  \n",
    "   Contains summary values for each ROI of the standards measurement. Must contain headers including a `ROI` column and one column per isotope ending with `sum (counts_pixel)`. Each row represents a single ROI from the standards acquisition.\n",
    "\n",
    "   **Example:**\n",
    "   <table>\n",
    "     <tr><th>ROI</th><th>56Fe sum (counts_pixel)</th><th>63Cu sum (counts_pixel)</th><th>...</th></tr>\n",
    "     <tr><td>1</td><td>1000</td><td>2000</td><td>...</td></tr>\n",
    "     <tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
    "     <tr><td>2</td><td>1500</td><td>2500</td><td>...</td></tr>\n",
    "     <tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
    "   </table>\n",
    "  \n",
    "3. **Amounts CSV**  \n",
    "   Contains known amounts for each element in the standards, used to calculate calibration slopes. Format: two columns without headers.  \n",
    "   First column is the element symbol (or `general`), second column is a comma-separated list of numeric amount values.  \n",
    "   If included, the 'general'column will by applied to any unmatched isotopes.\n",
    "\n",
    "   **Example:**\n",
    "   <table>\n",
    "     <tr><td>Fe</td><td>0.1, 0.2 ,0.3, 0.4, 0.5, 0.6, 0.7</td></tr>\n",
    "     <tr><td>Cu</td><td>0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35</td></tr>\n",
    "     <tr><td>...</td><td>...</td></tr>\n",
    "     <tr><td>general</td><td>0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7</td></tr>\n",
    "   </table>\n",
    "  \n",
    "**Workflow**  \n",
    "Upon uploading the files the notebook will:\n",
    "1. Match each isotope in the standards file to its corresponding element amounts.\n",
    "2. Combine all ROI values for each isotope and match them to the known amounts.\n",
    "3. Perform a linear regression (amounts vs. measured counts) for each isotope.\n",
    "4. Output regression statistics.\n",
    "5. Construct a summary DataFrame containing calibration slopes for each element symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5245f9-8949-4105-a109-6db9966796ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets\n",
    "singlecell_out = widgets.Output()\n",
    "standard_out = widgets.Output()\n",
    "amounts_out = widgets.Output()\n",
    "\n",
    "singlecell_upload = widgets.FileUpload(\n",
    "    accept=\".csv\",\n",
    "    multiple=True,\n",
    "    description=\"Upload single-cell CSVs\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    ")\n",
    "standard_upload = widgets.FileUpload(\n",
    "    accept=\".csv\",\n",
    "    multiple=False,\n",
    "    description=\"Upload standards summary CSV\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    ")\n",
    "amounts_upload = widgets.FileUpload(\n",
    "    accept=\".csv\",\n",
    "    multiple=False,\n",
    "    description=\"Upload amounts CSV\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    ")\n",
    "save_path_widget = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Enter working directory/desired save path\",\n",
    "    description=\"Path:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "\n",
    "def load_singlecell(change):\n",
    "    with singlecell_out:\n",
    "        clear_output(wait=True)\n",
    "        global singlecell_dfs\n",
    "        singlecell_dfs = []\n",
    "        for file_info in singlecell_upload.value:\n",
    "            content = file_info[\"content\"]\n",
    "            df = pd.read_csv(io.BytesIO(content))\n",
    "            singlecell_dfs.append(df)\n",
    "        print(f\"Loaded {len(singlecell_dfs)} single-cell file(s).\")\n",
    "\n",
    "\n",
    "singlecell_upload.observe(load_singlecell, names=\"value\")\n",
    "\n",
    "\n",
    "# laod standards\n",
    "def load_standards(change):\n",
    "    with standard_out:\n",
    "        clear_output(wait=True)\n",
    "        global standards_dict\n",
    "        standards_dict = {}\n",
    "        if standard_upload.value:\n",
    "            upload = standard_upload.value[0]\n",
    "            df_std = pd.read_csv(io.BytesIO(upload[\"content\"]))\n",
    "            name = upload[\"name\"].rsplit(\".\", 1)[0]\n",
    "            # split by ROI\n",
    "            for roi in df_std[\"ROI\"].unique():\n",
    "                sub = (\n",
    "                    df_std[df_std[\"ROI\"] == roi]\n",
    "                    .drop(columns=[\"ROI\"])\n",
    "                    .reset_index(drop=True)\n",
    "                )\n",
    "                key = f\"{name}_ROI_{roi}\"\n",
    "                standards_dict[key] = sub\n",
    "            display(df_std)\n",
    "            print(\"Standards loaded from ROIs:\")\n",
    "            for k in standards_dict:\n",
    "                print(f\" - {k}:\")\n",
    "\n",
    "\n",
    "standard_upload.observe(load_standards, names=\"value\")\n",
    "\n",
    "\n",
    "# load amounts\n",
    "def load_amounts(change):\n",
    "    with amounts_out:\n",
    "        clear_output(wait=True)\n",
    "        global element_x_values\n",
    "        element_x_values = {}\n",
    "        if amounts_upload.value:\n",
    "            upload = amounts_upload.value[0]\n",
    "            df_amt = pd.read_csv(io.BytesIO(upload[\"content\"]), header=None)\n",
    "            display(df_amt.head())\n",
    "            # parse comma-separated lists\n",
    "            element_x_values = {\n",
    "                el: np.fromstring(vals, sep=\",\") for el, vals in df_amt.values\n",
    "            }\n",
    "            if \"general\" not in element_x_values:\n",
    "                print(\n",
    "                    \"Warning: 'general' element not found. Unmatched elements may cause errors.\"\n",
    "                )\n",
    "            print(\"Amounts parsed successfully.\")\n",
    "\n",
    "\n",
    "amounts_upload.observe(load_amounts, names=\"value\")\n",
    "\n",
    "# Display widgets and outputs\n",
    "display(\n",
    "    widgets.VBox(\n",
    "        [\n",
    "            widgets.HBox([singlecell_upload]),\n",
    "            singlecell_out,\n",
    "            widgets.HBox([standard_upload]),\n",
    "            standard_out,\n",
    "            widgets.HBox([amounts_upload]),\n",
    "            amounts_out,\n",
    "            widgets.HBox([save_path_widget]),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression using ROI vectors per isotope with truncation on mismatch\n",
    "if not standards_dict or not element_x_values:\n",
    "    print(\"Please load both standards summary and amounts CSVs before running this cell.\")\n",
    "else:\n",
    "    results = {}\n",
    "    # Determine all isotope columns from any ROI\n",
    "    isotope_cols = set()\n",
    "    for df in standards_dict.values():\n",
    "        isotope_cols.update([col for col in df.columns if col.endswith('sum (counts_pixel)')])\n",
    "\n",
    "    for col in sorted(isotope_cols):\n",
    "        # Extract element symbol\n",
    "        m = re.search(r\"\\d{1,3}([A-Z][a-z]?)\", col)\n",
    "        if not m:\n",
    "            print(f\"{col}: pattern mismatch; skipping.\")\n",
    "            continue\n",
    "        sym = m.group(1)\n",
    "        # Retrieve amounts array\n",
    "        x_vals = element_x_values.get(sym)\n",
    "        if x_vals is None:\n",
    "            x_vals = element_x_values.get('general')\n",
    "            if x_vals is None:\n",
    "                print(f\"{col}: no amounts for '{sym}' or 'general'; skipping.\")\n",
    "                continue\n",
    "            print(f\"{col}: no entry for '{sym}'; using 'general' amounts of length {len(x_vals)}.\")\n",
    "        else:\n",
    "            print(f\"{col}: matched to '{sym}', amounts length {len(x_vals)}.\")\n",
    "\n",
    "        # Collect ROI-specific values for this isotope\n",
    "        y_vals = []\n",
    "        for key, df in standards_dict.items():\n",
    "            if col in df.columns:\n",
    "                # One summary value per ROI\n",
    "                y_vals.append(df[col].iloc[0])\n",
    "        print(f\"Collected {len(y_vals)} ROI values for '{col}'.\")\n",
    "\n",
    "        # Handle length mismatch by truncation\n",
    "        n_x, n_y = len(x_vals), len(y_vals)\n",
    "        if n_x != n_y:\n",
    "            n = min(n_x, n_y)\n",
    "            print(f\"Warning: length mismatch for '{col}' ({n_y} ROI vs {n_x} amounts), truncating to {n} points.\")\n",
    "            x = x_vals[:n]\n",
    "            y = y_vals[:n]\n",
    "        else:\n",
    "            x = x_vals\n",
    "            y = y_vals\n",
    "\n",
    "        # Run regression: amounts vs ROI-sums\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "        results[col] = {\n",
    "            'symbol': sym,\n",
    "            'slope': slope,\n",
    "            'intercept': intercept,\n",
    "            'r2': r_value**2,\n",
    "            'p_value': p_value,\n",
    "            'std_err': std_err\n",
    "        }\n",
    "        print(f\"Regression for '{col}': slope={slope:.4f}, intercept={intercept:.4f}, r2={r_value**2:.4f}\\n\")\n",
    "\n",
    "    # Construct DataFrame of slopes by element symbol\n",
    "    slopes_dict = {}\n",
    "    for stats in results.values():\n",
    "        symbol = stats['symbol']\n",
    "        slopes_dict[symbol] = stats['slope']\n",
    "    slope_df = pd.DataFrame([slopes_dict], index=['slope'])\n",
    "    print(\"All regressions complete across ROIs.\")\n",
    "    print(\"\\nQuantification factor DataFrame:\")\n",
    "    display(slope_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7c4d7-4f99-4e9d-8c95-29b2e5683329",
   "metadata": {},
   "source": [
    "## Pair standards with image channels\n",
    "\n",
    "The cell below provides widgets to match image channels to corresponding standard meassurements.  \n",
    "Upon uploading a standard file above, one first selects all required image channels from a list and subsequently matches them with the individual standards.  \n",
    "Optionally, a channel-specific factor can be applied.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7ef1a-8bda-4b89-837e-93dadb47b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_channels = widgets.SelectMultiple(\n",
    "    options=singlecell_dfs[0].columns,\n",
    "    description=\"Select features for quantification\",\n",
    "    disabled=False,\n",
    "    rows=10,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "quant_channels_selected = []\n",
    "\n",
    "def on_quant_channels_change(change):\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        quant_channels_selected.clear()\n",
    "        quant_channels_selected.extend(change[\"new\"])\n",
    "        update_group_options()\n",
    "\n",
    "quant_channels.observe(on_quant_channels_change, names=\"value\")\n",
    "display(quant_channels)\n",
    "\n",
    "# Assigns groups of channels to standard isotopes\n",
    "assignment_title = widgets.HTML(\"<b>Assign (groups of) cell features to a standard isotope</b>\")\n",
    "assignment_groups = {}\n",
    "group_widgets = []\n",
    "for std in list(slope_df.columns):\n",
    "    std_widget = widgets.SelectMultiple(\n",
    "         options=[],\n",
    "         description=f\"{std}:\",\n",
    "         rows=5,\n",
    "         style={\"description_width\": \"initial\"},\n",
    "         layout=widgets.Layout(width=\"auto\")\n",
    "    )\n",
    "    assignment_groups[std] = std_widget\n",
    "    group_widgets.append(std_widget)\n",
    "assignment_box = widgets.VBox(group_widgets)\n",
    "\n",
    "def update_group_options():\n",
    "    for std, widget in assignment_groups.items():\n",
    "        widget.options = quant_channels_selected\n",
    "\n",
    "display(assignment_title, assignment_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e36711-33da-4699-bee5-143e31e57202",
   "metadata": {},
   "source": [
    "### Quantify and plot channels of all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df = [df.copy() for df in singlecell_dfs]\n",
    "\n",
    "# Build mapping (channel -> standard)\n",
    "assignment_mapping = {}\n",
    "for std, widget in assignment_groups.items():\n",
    "    for channel in widget.value:\n",
    "        assignment_mapping[channel] = std\n",
    "\n",
    "# Build mapping of individual multiplication factors\n",
    "channel_mult_factors = {\n",
    "    channel: widget.value for channel, widget in assignment_groups.items()\n",
    "}\n",
    "\n",
    "# quantify each channel by applying corresponding standard slope\n",
    "for df in quant_df:\n",
    "    for channel, standard in assignment_mapping.items():\n",
    "        div_factor = slope_df.iloc[0][standard]\n",
    "        mult_factor = channel_mult_factors.get(channel, 1.0)\n",
    "        div_factor = float(slope_df.iloc[0, slope_df.columns.get_loc(standard)])\n",
    "        df[channel] = df[channel].astype(float) / div_factor * mult_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2efc1a-2c47-48c1-abb9-7ec2207b91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quantified data\n",
    "fig, axs = plt.subplots(\n",
    "    len(quant_channels_selected), len(quant_df), figsize=(16, 9), sharey=False\n",
    ")\n",
    "\n",
    "\n",
    "# Ensure axs is a 2D array\n",
    "def ensure_2d_axs(axs):\n",
    "    if axs.ndim == 1:\n",
    "        if len(quant_channels_selected) == 1 or len(quant_df) == 1:\n",
    "            return axs.reshape(len(quant_channels_selected), len(quant_df))\n",
    "    return axs\n",
    "\n",
    "\n",
    "axs = ensure_2d_axs(axs)\n",
    "\n",
    "# Extracting single cell file names\n",
    "uploaded_filenames = [file_dict[\"name\"] for file_dict in singlecell_upload.value]\n",
    "\n",
    "for i, c in enumerate(quant_channels_selected):\n",
    "    for j, df in enumerate(quant_df):\n",
    "        ax = sns.histplot(df, x=c, ax=axs[i, j])\n",
    "        ax.set(xlabel=f\"{c} content in fg/cell\")\n",
    "\n",
    "        if j == 0:\n",
    "            ax.set(ylabel=\"Cell Count\")\n",
    "\n",
    "        ax.set_title(f\"Quantified {c} distribution of {uploaded_filenames[j][:-4]}\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b1ccb-05e5-48a4-8bdc-32051119b938",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Uncomment the cell below to save individual histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e95f1f-33da-411a-a83a-6a768be0f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, df in enumerate(quant_df):\n",
    "#     for c in quant_channels.value:\n",
    "#         ax = sns.displot(df, x=c)\n",
    "\n",
    "#         file_name = list(singlecell_upload.value[idx].values())[0]\n",
    "#         file_base_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "#         plt.title(f\"Quantified {c} distribution of {file_base_name}\")\n",
    "#         ax.set(xlabel=f\"{c} content in fg/cell\", ylabel=\"Cell Count\")\n",
    "#         ax.figure.tight_layout()\n",
    "\n",
    "#         save_path = os.path.join(\n",
    "#             save_path_widget.value, f\"{file_base_name}_quantified_{c}_hist.png\"\n",
    "#         )\n",
    "#         plt.savefig(fname=save_path, dpi=600)\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae189f2-cf44-4c06-897c-ac317ce09664",
   "metadata": {},
   "source": [
    "### Uncomment the cell below to save quantified data as .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d9183-c35a-4eb9-84e2-79849c1e407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, df in enumerate(quant_df):\n",
    "#     df_copy = df.copy()\n",
    "\n",
    "#     rename_dict = {c: c + \"_quantified\" for c in quant_channels.value}\n",
    "#     df_copy.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "#     file_name = list(singlecell_upload.value[idx].values())[0]\n",
    "#     file_base_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "#     save_path = os.path.join(save_path_widget.value, f\"{file_base_name}_quantified.csv\")\n",
    "#     df_copy.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scimap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
