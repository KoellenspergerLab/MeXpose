{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30b637-6f66-4af0-b4de-dc76a23cebfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from io import BytesIO\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import clear_output, display\n",
    "from scipy.stats import linregress\n",
    "from sklearn.utils import resample\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d381f6f-3d48-4a4a-a934-ccb89da222b3",
   "metadata": {},
   "source": [
    "## Limit-of-Detection\n",
    "This notebook calculates area based limits-of-detection (LOD) for laser ablation inductively coupled mass spectrometry data.  \n",
    "In the process it clips negative data to 0 for better estimation of normality.  \n",
    "  \n",
    "Two CSV files are required:  \n",
    "1. A file containing pixels of exported ROIs (from the image_reconstruction notebook). ROIs represent the measured standards ranging from blank to varying concentrations.\n",
    "2. A 'amounts file' containing the absolut amounts of the individual standard element per standard measurement.\n",
    "\n",
    "**Amounts file explanation**  \n",
    "Standard elements must be given in the canonical abbreviated nomenclature i.e. **Pt** (=Platinum), **Fe** (=iron), **Co** (=Cobalt) etc.  \n",
    "The file should contain 2 columns. The first holds the abbreviated element title, the second is a comma-separated list of the amounts (fg) of the element per standard measurement.  \n",
    "A '**general**' row can be added which will apply to any standard elements that could not be matched to a measured isotope.\n",
    "  \n",
    "Below is an example of the format:    \n",
    "<table>\n",
    "  <tr>\n",
    "    <td>Pt</td>\n",
    "    <td>0.0, 2.47, 4.87, 9.41, 23.21, 46.36, 92.69</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Fe</td>\n",
    "    <td>0.0, 3.68, 6.49, 15.63, 27.38, 36.53, 45.36</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Co</td>\n",
    "    <td>0.0, 3.68, 6.49, 15.63, 27.38, 36.53, 45.36</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>general</td>\n",
    "    <td>0.0, 3.55, 6.41, 15.58, 27.23, 36.33, 45.24</td>\n",
    "  </tr>\n",
    "</table>\n",
    "  \n",
    "\n",
    "Set your output directory in the input field of the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a311e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = widgets.Text(\n",
    "    placeholder=\"Path...\",\n",
    "    description=\"Output directory:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"40%\"),\n",
    ")\n",
    "display(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adf475-1e1d-4409-bd5c-d180a102bd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standards_dict = {}\n",
    "\n",
    "# widgets\n",
    "output = widgets.Output()\n",
    "\n",
    "standard_upload = widgets.FileUpload(\n",
    "    accept='.csv',\n",
    "    multiple=False,\n",
    "    description='Upload standard CSV',\n",
    "    layout=widgets.Layout(width='auto'),\n",
    ")\n",
    "display(standard_upload, output)\n",
    "\n",
    "def on_upload(change):\n",
    "    global standards_dict\n",
    "    standards_dict.clear()\n",
    "\n",
    "    # check\n",
    "    if standard_upload.value:\n",
    "        uploaded_file = standard_upload.value[0]\n",
    "        standard_df = pd.read_csv(BytesIO(uploaded_file.content))\n",
    "        standard_name = standard_upload.value[0].name[0:-4]  # remove .csv extension\n",
    "        \n",
    "        # split by ROI\n",
    "        for roi in standard_df['ROI'].unique():\n",
    "            sub = standard_df[standard_df['ROI'] == roi].drop(columns=['ROI']).reset_index(drop=True)\n",
    "            key = f\"{standard_name}_ROI_{roi}\"\n",
    "            standards_dict[key] = sub\n",
    "\n",
    "        # Feedback\n",
    "        with output:\n",
    "            display(standard_df)\n",
    "            print(\"standards_dict keys:\")\n",
    "            for k in standards_dict:\n",
    "                print(f\" {k}: {standards_dict[k].shape[0]}x{standards_dict[k].shape[1]}\")\n",
    "\n",
    "# Wire the callback\n",
    "standard_upload.observe(on_upload, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f7784-a8d0-41c6-8263-a944264e17c1",
   "metadata": {},
   "source": [
    "## Element selection\n",
    "\n",
    "**Note:**  \n",
    "The list below shows all the measured **isotopes**. However, most standards are not isotopically pure, one is effectively selecting **elements** for LOD calculation.  \n",
    "The same calibration will be applied to all isotopes of any selected element.  \n",
    "Additionally, negative values will be clipped to 0 in the cell below the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a81019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blk_select = widgets.RadioButtons(\n",
    "    options=standards_dict.keys(),\n",
    "    description=\"Blank ROI\",\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "\n",
    "columns_select = widgets.SelectMultiple(\n",
    "    options=list(standards_dict.values())[0],\n",
    "    description=\"Isotopes\",\n",
    "    rows=20,\n",
    "    layout={\"width\": \"auto\"},\n",
    ")\n",
    "\n",
    "display(widgets.HBox([columns_select, blk_select]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe0181-dcd4-4623-92d0-8d4fc00975ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduced_standards = {}\n",
    "\n",
    "cleaned_columns = [col.strip() for col in columns_select.value]\n",
    "\n",
    "for key, df in standards_dict.items():\n",
    "    reduced = df[cleaned_columns].copy()\n",
    "    reduced = reduced.clip(lower=0)\n",
    "    reduced_standards[f\"{key}_reduced\"] = reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca509229",
   "metadata": {},
   "source": [
    "## Plot a raw histogram for the selected isotope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets\n",
    "standard_select = widgets.Dropdown(\n",
    "    options=list(reduced_standards.keys()),\n",
    "    value=list(reduced_standards.keys())[0],\n",
    "    description=\"Select Standard\",\n",
    "    layout={\"width\": \"max-content\"},\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "histogram_select = widgets.RadioButtons(\n",
    "    options=[],\n",
    "    description=\"Histogram channel\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "\n",
    "# callbacks\n",
    "def initialise_plot(df):\n",
    "    cols = list(df.columns)\n",
    "    histogram_select.options = cols\n",
    "    histogram_select.value = cols[0]\n",
    "    draw_histogram(df, cols[0])\n",
    "\n",
    "\n",
    "def draw_histogram(df, col):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure()\n",
    "        plt.hist(df[col].dropna(), bins=50)\n",
    "        plt.title(f\"{col} distribution\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def on_standard_change(change):\n",
    "    df = reduced_standards[change[\"new\"]]\n",
    "    initialise_plot(df)\n",
    "\n",
    "\n",
    "def on_channel_change(change):\n",
    "    df = reduced_standards[standard_select.value]\n",
    "    draw_histogram(df, change[\"new\"])\n",
    "\n",
    "\n",
    "# observers\n",
    "standard_select.observe(on_standard_change, names=\"value\")\n",
    "histogram_select.observe(on_channel_change, names=\"value\")\n",
    "\n",
    "display(standard_select, histogram_select, plot_output)\n",
    "\n",
    "initialise_plot(reduced_standards[standard_select.value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648a4c2",
   "metadata": {},
   "source": [
    "## Outlier filtering\n",
    "\n",
    "The following section performs outlier filtering either based on set percentiles or on Z-scores (standard scores).\n",
    "\n",
    "Percentiles method: Outliers are determined by the percentile of the data. Everything below the 'Lower percentile' and above the 'Upper percentile' is considered an outlier.\n",
    "\n",
    "Z-score method: A z-score represents how many standard deviations a data point is from the mean. This function uses z-scores indirectly by calculating the threshold as mean + n_std * standard deviation. Data points above this threshold are considered outliers. By setting the 'Number of std' you can specify how strict or lenient you want the outlier determination to be. A smaller value of n_std would be stricter, catching more outliers, whereas a larger value would be more lenient. A value of 3 would retain to 99.7% of the data.\n",
    "\n",
    "**NOTE**: Z-scores are especially useful if your data is normally distributed. Percentiles are more data-driven and can be applied without assumptions about the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfe2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_percentiles(column, upper_quant, lower_quant):\n",
    "    q_low = column.quantile(lower_quant)\n",
    "    q_hi = column.quantile(upper_quant)\n",
    "    non_outliers = column[(column >= q_low) & (column <= q_hi)].reset_index(drop=True)\n",
    "    outliers = column[(column < q_low) | (column > q_hi)].reset_index(drop=True)\n",
    "    print(f\"Column: {column.name}, Lower Quantile: {q_low}, Upper Quantile: {q_hi}\")\n",
    "    print(f\"Non-Outliers: {len(non_outliers)}, Outliers: {len(outliers)}\")\n",
    "    return non_outliers, outliers\n",
    "\n",
    "\n",
    "def remove_outliers_zscore(column, n_std):\n",
    "    mean = column.mean()\n",
    "    sd = column.std()\n",
    "    non_outliers = column[(column <= mean + (n_std * sd))].reset_index(drop=True)\n",
    "    outliers = column[(column > mean + (n_std * sd))].reset_index(drop=True)\n",
    "    print(f\"Non-Outliers: {len(non_outliers)}, Outliers: {len(outliers)}\")\n",
    "    return non_outliers, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_clean = blk_select.value + \"_reduced\"\n",
    "blk_columns = reduced_standards[blk_clean]\n",
    "    \n",
    "    \n",
    "isotope_select = widgets.SelectMultiple(\n",
    "    options=list(blk_columns.columns),\n",
    "    description=\"Isotopes:\",\n",
    "    rows=10,\n",
    "    layout={\"width\": \"auto\"},\n",
    ")\n",
    "outlier_method = widgets.RadioButtons(\n",
    "    options=[\"Percentiles\", \"Z-Score\"],\n",
    "    description=\"Outlier Method:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "n_std_select = widgets.FloatText(\n",
    "    value=3.0,\n",
    "    min=0.0,\n",
    "    step=0.1,\n",
    "    description=\"Number of standard deviations:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "upper_quant_select = widgets.FloatText(\n",
    "    value=0.997,\n",
    "    min=0.000,\n",
    "    step=0.001,\n",
    "    description=\"Upper percentile limit:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "lower_quant_select = widgets.FloatText(\n",
    "    value=0.000,\n",
    "    min=0.000,\n",
    "    step=0.001,\n",
    "    description=\"Lower percentile limit:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "row1 = widgets.HBox([isotope_select, outlier_method])\n",
    "row2 = widgets.HBox([n_std_select, upper_quant_select, lower_quant_select])\n",
    "\n",
    "layout = widgets.VBox([row1, row2])\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare empty DataFrames\n",
    "outliers_df = pd.DataFrame()\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "# Choose removal function\n",
    "if outlier_method.value == \"Percentiles\":\n",
    "    remover = remove_outliers_percentiles\n",
    "    params = (float(upper_quant_select.value), float(lower_quant_select.value))\n",
    "    method_name = \"percentiles\"\n",
    "else:\n",
    "    remover = remove_outliers_zscore\n",
    "    params = (int(n_std_select.value),)\n",
    "    method_name = \"z-score\"\n",
    "\n",
    "# Process each column\n",
    "for column in isotope_select.value:\n",
    "    print(f\"Processing '{column}' using {method_name}:\")\n",
    "    series = blk_columns[column]\n",
    "    \n",
    "    print(\"Original data summary:\")\n",
    "    print(series.describe(), \"\\n\")\n",
    "    \n",
    "    filtered_col, outliers_col = remover(series, *params)\n",
    "    filtered_df[column] = filtered_col\n",
    "    outliers_df[column] = outliers_col\n",
    "    \n",
    "    print(f\"Removed {len(outliers_col)} outlier(s).\")\n",
    "    print(\"Filtered data summary:\")\n",
    "    print(filtered_col.describe(), \"\\n\")\n",
    "    print(\"Outliers data summary:\")\n",
    "    print(outliers_col.describe(), \"\\n\")\n",
    "\n",
    "# Merge filtered results\n",
    "merged_df = blk_columns.copy()\n",
    "merged_df[filtered_df.columns] = filtered_df\n",
    "\n",
    "# Store result\n",
    "reduced_standards[blk_clean] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7800c",
   "metadata": {},
   "source": [
    "### Display histrogram of filtered data\n",
    "Requires outlier filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47783e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output = widgets.Output()\n",
    "\n",
    "# Display\n",
    "display(widgets.VBox([histogram_select, plot_output]))\n",
    "initialise_plot(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9919b4",
   "metadata": {},
   "source": [
    "### Amounts file upload\n",
    "This cell requires a CSV file upload. The file should contain the ground truth of the amounts of the individual standard element per standard measurement.  \n",
    "Standard elements must be given in the canonical abbreviated nomenclature i.e. **Pt** (=Platinum), **Fe** (=iron), **Co** (=Cobalt) etc.  \n",
    "The file should contain 2 columns. The first holds the abbreviated element title, the second is a comma-separated list of the amount of the element per standard measurement.  \n",
    "A '**general**' row can be added which will apply to any standard elements that could not be matched to a measured isotope.\n",
    "  \n",
    "Below is an example of the format:    \n",
    "<table>\n",
    "  <tr>\n",
    "    <td>Pt</td>\n",
    "    <td>0.0, 2.47, 4.87, 9.41, 23.21, 46.36, 92.69</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Fe</td>\n",
    "    <td>0.0, 3.68, 6.49, 15.63, 27.38, 36.53, 45.36</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Co</td>\n",
    "    <td>0.0, 3.68, 6.49, 15.63, 27.38, 36.53, 45.36</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>general</td>\n",
    "    <td>0.0, 3.55, 6.41, 15.58, 27.23, 36.33, 45.24</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bac3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_widget = widgets.Output()\n",
    "upload_button = widgets.FileUpload(\n",
    "    accept=\".csv\",\n",
    "    multiple=False,\n",
    "    description=\"Upload amounts CSV\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "def on_csv_upload(change):\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        if not upload_button.value:\n",
    "            return\n",
    "        # read CSV\n",
    "        uploaded_file = upload_button.value[0]\n",
    "        content = uploaded_file[\"content\"]\n",
    "        df = pd.read_csv(BytesIO(content), header=None)\n",
    "        print(\"CSV head:\")\n",
    "        print(df.head(), \"\\n\")\n",
    "\n",
    "        # parse x_values\n",
    "        global element_x_values\n",
    "        element_x_values = {}\n",
    "        element_x_values = {\n",
    "            element: np.fromstring(vals, sep=\",\") for element, vals in df.values\n",
    "        }\n",
    "        if \"general\" not in element_x_values:\n",
    "            print(\n",
    "                \"Warning: 'general' element not found. Unmatched elements will cause errors.\"\n",
    "            )\n",
    "\n",
    "        print(\"Parsed element_x_values successfully!\")\n",
    "\n",
    "\n",
    "upload_button.observe(on_csv_upload, names=\"value\")\n",
    "display(upload_button, output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b886786",
   "metadata": {},
   "source": [
    "###  LOD calculations\n",
    "The following cell computes limits of detection (LOD) based on the underlying distrubution of sumed area (**pixels**) of the blank.  \n",
    "Depending on whether the data is gaussian or compound poisson distributed a different formula will be applied for LOD calculation.\n",
    "- Gaussian: 3*sigma\n",
    "- Compound poisson: approximated by poisson 3.29*sigma + 2.71\n",
    "\n",
    "The decission is made based on a heuristic threshold (**normality_threshold**).  \n",
    "For a more in-depth explanation please refere to Föls et al. 2025 (in preperation).  \n",
    "Bootstrapping parameters can be adjusted in the cell below.\n",
    "- **\"iterations\"** should be between 1000 - 10000\n",
    "- **\"pixels\"** should reflect your cell size in pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4974a4-41b7-4463-9c0a-88e70720e6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "pixels = 200\n",
    "normality_threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir.value, exist_ok=True)\n",
    "log_path = os.path.join(output_dir.value, \"bootstrap_log.log\")\n",
    "\n",
    "with open(log_path, \"w\") as log:\n",
    "\n",
    "    def get_x_vals(col, x_vals_dict, log):\n",
    "        # Extract element symbol from strings and return corresponding x_values\n",
    "        m = re.search(r\"(\\d{1,3})([A-Z][a-z]?)\", col)\n",
    "        if m:\n",
    "            symbol = m.group(2)\n",
    "            if symbol in x_vals_dict:\n",
    "                return x_vals_dict[symbol]\n",
    "            else:\n",
    "                log.write(f\"No element amounts entry for '{symbol}'; \")\n",
    "        else:\n",
    "            log.write(f\"No isotope+element match in '{col}'; \")\n",
    "\n",
    "        # fallback to general if present\n",
    "        general = x_vals_dict.get(\"general\")\n",
    "        if general is not None:\n",
    "            log.write(\"using 'general'.\\n\")\n",
    "            return general\n",
    "\n",
    "        # no match at all\n",
    "        log.write(\"and no 'general' defined; skipping.\\n\")\n",
    "        return None\n",
    "\n",
    "    # create output subfolder\n",
    "    folder = f\"{iterations}_iter_{pixels}px_sums\"\n",
    "    fp = os.path.join(output_dir.value, folder)\n",
    "    os.makedirs(fp, exist_ok=True)\n",
    "    log.write(f\"\\n=== {folder} ===\\n\")\n",
    "\n",
    "    # Determine blank\n",
    "    try:\n",
    "        blank_key = blk_select.value + \"_reduced\"\n",
    "        if blank_key not in reduced_standards:\n",
    "            raise KeyError\n",
    "    except Exception:\n",
    "        log.write(\"blk_select undefined or invalid; using first ROI as blank.\\n\")\n",
    "        blank_key = next(iter(reduced_standards))\n",
    "\n",
    "    for col in cleaned_columns:\n",
    "        log.write(f\"\\nColumn '{col}' — {iterations}x{pixels}:\\n\")\n",
    "\n",
    "        # X‐values transform\n",
    "        x_vals = get_x_vals(col, element_x_values, log)\n",
    "        if x_vals is None:\n",
    "            log.write(f\"  Skipping calculation for '{col}' (no amounts).\\n\")\n",
    "            continue\n",
    "\n",
    "        n_standards = len(reduced_standards)\n",
    "        n_xvals = len(x_vals)\n",
    "        if n_xvals != n_standards:\n",
    "            log.write(\n",
    "                f\"  Warning for '{col}': \"\n",
    "                f\"{n_xvals} amounts vs {n_standards} standards; \"\n",
    "                \"truncating to the shorter length.\\n\"\n",
    "            )\n",
    "\n",
    "        transformed = [\n",
    "            (x / len(df)) * pixels for x, df in zip(x_vals, reduced_standards.values())\n",
    "        ]\n",
    "        log.write(f\"  Original amounts: {x_vals}\\n\")\n",
    "        log.write(f\"  Transformed: {transformed}\\n\")\n",
    "\n",
    "        # bootstrap sums\n",
    "        sums_dict = {}\n",
    "        for name, df in reduced_standards.items():\n",
    "            series = df[col].dropna()\n",
    "            m = re.match(r\"(.+)_ROI_(.+)_reduced$\", name)\n",
    "            if not m:\n",
    "                raise ValueError(f\"Key format unexpected: '{name}'\")\n",
    "            roi_label = m.group(2)\n",
    "\n",
    "            if name == blank_key:\n",
    "                label = f\"{col}_blk_sums\"\n",
    "            else:\n",
    "                label = f\"{col}_ROI_{roi_label}_sums\"\n",
    "\n",
    "            boot_sums = [\n",
    "                resample(series, replace=True, n_samples=pixels).sum()\n",
    "                for _ in range(iterations)\n",
    "            ]\n",
    "            sums_dict[label] = boot_sums\n",
    "            log.write(f\"  {label}: {len(boot_sums)} samples\\n\")\n",
    "\n",
    "        combined = pd.DataFrame(sums_dict).dropna()\n",
    "\n",
    "        # statistics & normality\n",
    "        means = combined.mean()\n",
    "        stds = combined.std()\n",
    "        blk_label = f\"{col}_blk_sums\"\n",
    "        if blk_label not in means:\n",
    "            raise KeyError(f\"Blank column '{blk_label}' missing\")\n",
    "\n",
    "        normality = (\n",
    "            \"normal\"\n",
    "            if means[blk_label] >= normality_threshold\n",
    "            else \"not normal/poisson\"\n",
    "        )\n",
    "        log.write(f\"  Normality ({blk_label}): {normality}\\n\")\n",
    "\n",
    "        # regression\n",
    "        slope, intercept, r_val, _, _ = linregress(transformed, means)\n",
    "        r2 = r_val**2\n",
    "        log.write(\n",
    "            f\"  Regression: slope={slope:.3f}, \"\n",
    "            f\"intercept={intercept:.3f}, R²={r2:.3f}\\n\"\n",
    "        )\n",
    "\n",
    "        # LOD calculation\n",
    "        if normality == \"normal\":  # gaussian\n",
    "            lod_cts = stds[blk_label] * 3\n",
    "        else:  # poisson\n",
    "            lod_cts = stds[blk_label] * 3.29 + 2.71\n",
    "        lod_fg = lod_cts / slope\n",
    "        log.write(f\"  LOD cts: {lod_cts:.3f}, LOD fg: {lod_fg:.3f}\\n\")\n",
    "\n",
    "        # save results\n",
    "        result = pd.concat(\n",
    "            [\n",
    "                combined,\n",
    "                pd.DataFrame({f\"{col}_normality\": [normality]}),\n",
    "                means.rename(lambda c: f\"{c}_mean\").to_frame().T,\n",
    "                stds.rename(lambda c: f\"{c}_std\").to_frame().T,\n",
    "                pd.DataFrame(\n",
    "                    {\"Slope\": [slope], \"Intercept\": [intercept], \"R_squared\": [r2]}\n",
    "                ),\n",
    "                pd.DataFrame({\"LOD_cts\": [lod_cts], \"LOD_fg\": [lod_fg]}),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        fname = f\"{col}_{iterations}iter_{pixels}px_results.csv\"\n",
    "        fname = re.sub(r\"[\\\\/]\", \"_\", fname)\n",
    "        result.to_csv(os.path.join(fp, fname), index=False)\n",
    "        log.write(f\"  Saved CSV: {fname}\\n\")\n",
    "\n",
    "print(f\"Bootstrapping complete;\\n log and results at: {log_path} and {fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62065c32",
   "metadata": {},
   "source": [
    "### Histogram and QQ-plot visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for results\n",
    "aggregated_base = output_dir.value\n",
    "\n",
    "# Widgets\n",
    "folder_select = widgets.Dropdown(\n",
    "    options=[f for f in os.listdir(aggregated_base)\n",
    "             if os.path.isdir(os.path.join(aggregated_base, f))],\n",
    "    description=\"Results Folder:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "file_select = widgets.Dropdown(description=\"Files:\")\n",
    "column_select = widgets.Dropdown(description=\"Columns:\")\n",
    "plot_type_select = widgets.ToggleButtons(\n",
    "    options=[\"Histogram\", \"QQ-Plot\"],\n",
    "    description=\"Plot Type:\",\n",
    ")\n",
    "plot_output = widgets.Output()\n",
    "save_name = widgets.Text(value=\"plot\", description=\"Save as:\")\n",
    "save_button = widgets.Button(description=\"Save Plot\", icon=\"save\")\n",
    "\n",
    "current_fig = None\n",
    "\n",
    "def refresh_files(change):\n",
    "    folder = folder_select.value\n",
    "    path = os.path.join(aggregated_base, folder)\n",
    "    files = [f for f in os.listdir(path) if f.endswith(\"_results.csv\")]\n",
    "    file_select.options = files\n",
    "    file_select.value = files[0] if files else None\n",
    "\n",
    "def refresh_columns(change):\n",
    "    folder = folder_select.value\n",
    "    fname = file_select.value\n",
    "    if not fname:\n",
    "        column_select.options = []\n",
    "        return\n",
    "    df = pd.read_csv(os.path.join(aggregated_base, folder, fname))\n",
    "    cols = list(df.columns)\n",
    "    column_select.options = cols\n",
    "    column_select.value = cols[0] if cols else None\n",
    "\n",
    "def update_plot(change):\n",
    "    global current_fig\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        folder = folder_select.value\n",
    "        fname = file_select.value\n",
    "        col = column_select.value\n",
    "        if not (folder and fname and col):\n",
    "            return\n",
    "        df = pd.read_csv(os.path.join(aggregated_base, folder, fname))\n",
    "        \n",
    "        # plot histogram or QQ-Plot\n",
    "        if plot_type_select.value == \"Histogram\":\n",
    "            fig, ax = plt.subplots(figsize=(8,5), dpi=100)\n",
    "            sns.histplot(df[col], kde=True, ax=ax)\n",
    "            ax.set_title(f\"Histogram of {col}\")\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(8,5), dpi=100)\n",
    "            clean = df[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            sm.qqplot(clean, line=\"45\", ax=ax, fit=True)\n",
    "            ax.set_title(f\"QQ-Plot of {col}\")\n",
    "            ax.set_xlabel(\"Theoretical Quantiles\")\n",
    "            ax.set_ylabel(\"Sample Quantiles\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        current_fig = fig\n",
    "\n",
    "def save_plot(btn):\n",
    "    if current_fig:\n",
    "        fname = save_name.value.strip() or \"plot\"\n",
    "        outp = os.path.join(aggregated_base, folder_select.value, f\"{fname}.png\")\n",
    "        current_fig.savefig(outp, dpi=300)\n",
    "        with plot_output:\n",
    "            print(f\"Saved plot to {outp}\")\n",
    "\n",
    "# Observers\n",
    "folder_select.observe(refresh_files, names=\"value\")\n",
    "file_select.observe(refresh_columns, names=\"value\")\n",
    "for w in (file_select, column_select, plot_type_select):\n",
    "    w.observe(update_plot, names=\"value\")\n",
    "save_button.on_click(save_plot)\n",
    "\n",
    "# Display\n",
    "controls = widgets.VBox([folder_select, file_select, column_select, plot_type_select])\n",
    "saver = widgets.HBox([save_name, save_button])\n",
    "display(controls, plot_output, saver)\n",
    "\n",
    "# Initialize\n",
    "if folder_select.options:\n",
    "    folder_select.value = folder_select.options[0]\n",
    "    refresh_files(None)\n",
    "    refresh_columns(None)\n",
    "    update_plot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27604412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scimap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
